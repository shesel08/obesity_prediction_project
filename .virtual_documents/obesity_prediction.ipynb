import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.tree import DecisionTreeClassifier
from tqdm import tqdm
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import accuracy_score


dataset = pd.read_csv('obesity_data.csv')
dataset.head()


# Data Exploration
dataset.describe()


dataset.info()


dataset.isnull().sum()


dataset.info()


plt.figure(figsize=(6, 6))  # Set the figure size
sns.countplot(x="Gender", data=dataset, palette="Set1")  # Use a visually appealing color palette
plt.xlabel("Gender")
plt.ylabel("Count")
plt.title("Gender Distribution")
plt.show()


plt.figure(figsize=(6, 6))  # Set the figure size
sns.countplot(x="ObesityCategory", data=dataset, palette="tab10")  # Use a visually appealing color palette
plt.xlabel("Obesity Category")
plt.ylabel("Count")
plt.title("Distribution of obesity categories")
plt.show()


print(sns.__version__)
corr = dataset.drop(["Gender", "ObesityCategory"], axis=1).corr()
sns.heatmap(corr, annot=True)
plt.show()


#Label Encoding
label_encoder = LabelEncoder()
dataset['Gender'] = label_encoder.fit_transform(dataset['Gender'])


X, y = dataset.drop(['ObesityCategory'], axis =1), dataset['ObesityCategory']


decision_tree_classifier = DecisionTreeClassifier()


### Split test data for later testing before training
train, test, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)


k_folds = 10
stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)


for train_index, test_index in tqdm(stratified_kfold.split(train, train_y), total=k_folds, desc="Cross-validation"):
    X_train, X_test = train.iloc[train_index], train.iloc[test_index]
    y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]

    decision_tree_classifier.fit(X_train, y_train)

    y_pred = decision_tree_classifier.predict(X_test)

    print(confusion_matrix(y_test, y_pred))
    print(classification_report(y_test, y_pred))


y_pred = decision_tree_classifier.predict(test)

print(confusion_matrix(test_y, y_pred))
print(classification_report(test_y, y_pred))


# Calculate the accuracy ofthe model
accuracy = accuracy_score(test_y, y_pred)
accuracy
